{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/sr7037/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/sr7037/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/sr7037/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "nltk.download([\"punkt\",\"stopwords\",\"wordnet\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecommendationSystem:\n",
    "    def __init__(self):\n",
    "        self.movies = pd.read_csv(\"movies.csv\")\n",
    "        self.ratings = pd.read_csv(\"ratings.csv\")\n",
    "        self.dataset = self.movies.merge(self.ratings)\n",
    "        \n",
    "    def sort_movies_by_year(self,li):\n",
    "        def merge_sort(a,l,r):\n",
    "            if l==r:\n",
    "                return\n",
    "            mid=(l+r)//2\n",
    "            merge_sort(a,l,mid)\n",
    "            merge_sort(a,mid+1,r)\n",
    "            merge(a,l,mid,r)\n",
    "\n",
    "        def merge(a,l,mid,r):\n",
    "            n1=mid-l+1\n",
    "            n2=r-(mid+1)+1\n",
    "            L=[a[i+l] for i in range(n1)]\n",
    "            R=[a[i+mid+1] for i in range(n2)]\n",
    "            i,j,k=0,0,l\n",
    "            while(i<n1 and j<n2):\n",
    "                if int(L[i][-5:-1])>int(R[j][-5:-1]) :\n",
    "                    a[k]=L[i]\n",
    "                    i+=1\n",
    "                else:\n",
    "                    a[k]=R[j]\n",
    "                    j+=1\n",
    "                k+=1\n",
    "            while(i<n1):\n",
    "                a[k]=L[i]\n",
    "                i+=1\n",
    "                k+=1\n",
    "            while(j<n2):\n",
    "                a[k]=R[j]\n",
    "                j+=1\n",
    "                k+=1\n",
    "        merge_sort(li,0,len(li)-1)\n",
    "    \n",
    "    \n",
    "    def get_movie_by_id(self,mv_id):\n",
    "        return self.movies.loc[rs.movies['movieId']==mv_id,['title']].values[0][0]\n",
    "    \n",
    "    \n",
    "    def clean_feature_and_return_ndarray(self,genres):\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        li=[]\n",
    "        for i in range(len(genres)):\n",
    "            temp = genres[i].lower()\n",
    "            temp = temp.split(\"|\")\n",
    "            temp = [lemmatizer.lemmatize(word) for word in temp]\n",
    "            li.append(\" \".join(temp))\n",
    "        \n",
    "        cv = CountVectorizer()\n",
    "        return cv.fit_transform(li).toarray(),cv,li\n",
    "        \n",
    "    def content_based_filtering(self,userId,no_of_movies=15):\n",
    "        #Finding based on similar movies\n",
    "        \n",
    "        X,cv,li = self.clean_feature_and_return_ndarray(self.movies[\"genres\"])\n",
    "        movies_dataset = pd.DataFrame(li,columns=[\"genres\"],index=self.movies[\"title\"])\n",
    "        \n",
    "        \n",
    "        def get_movie_by_index(movies_dataset,idx):   \n",
    "            return movies_dataset.index[idx]\n",
    "        \n",
    "        similarities = cosine_similarity(X)\n",
    "        \n",
    "        def latest_movieId_watched(uid):\n",
    "            time = self.ratings.loc[self.ratings[\"userId\"]==uid,[\"movieId\",\"timestamp\"]]\n",
    "            return time.sort_values(by=\"timestamp\",ascending=False)[\"movieId\"].values[0]\n",
    "        \n",
    "        latest_movieId_watched_by_user = latest_movieId_watched(userId)\n",
    "        movie_index = self.movies.loc[self.movies['movieId']==latest_movieId_watched_by_user,[\"title\"]].index[0]\n",
    "        similarity_values = pd.Series(similarities[movie_index])\n",
    "        \n",
    "        similar_movie_indexes = list(similarity_values.sort_values(ascending=False).index)\n",
    "        similar_movie_indexes.remove(movie_index)\n",
    "        \n",
    "        li = [get_movie_by_index(movies_dataset,idx) for idx in similar_movie_indexes]\n",
    "        li = li[:no_of_movies]\n",
    "        \n",
    "        self.sort_movies_by_year(li)\n",
    "        \n",
    "        print(\"Since u have watched --->\",self.get_movie_by_id(latest_movieId_watched_by_user),\"<--- We recommend you\",end=\"\\n\\n\")\n",
    "        \n",
    "        \n",
    "        for i in range(no_of_movies):\n",
    "            print(li[i])\n",
    "        \n",
    "        return li\n",
    "    \n",
    "    def collaborative_filtering(self,uid,no_of_movies=15):\n",
    "        #Finding based on similar users\n",
    "        \n",
    "        X,cv,li = self.clean_feature_and_return_ndarray(self.dataset['genres'])\n",
    "        genres = pd.DataFrame(X,columns=cv.get_feature_names())\n",
    "        \n",
    "        users = pd.DataFrame(self.dataset['userId'],columns=['userId'])\n",
    "        users = users.join(genres)\n",
    "        \n",
    "        users_moviemat = users.groupby(\"userId\").sum()\n",
    "        X = users_moviemat.iloc[:,:].values\n",
    "\n",
    "        classifier = NearestNeighbors()\n",
    "        classifier.fit(X)\n",
    "        \n",
    "        li = classifier.kneighbors([X[uid-1]],n_neighbors=5,return_distance=False)\n",
    "        current_user = self.dataset.loc[self.dataset[\"userId\"]==li[0][0],:][\"title\"].values\n",
    "        similar_user = self.dataset.loc[self.dataset[\"userId\"]==li[0][1],:][\"title\"].values\n",
    "        \n",
    "        \n",
    "        movies_list = [movie for movie in similar_user if movie not in current_user]\n",
    "        \n",
    "        self.sort_movies_by_year(movies_list)\n",
    "        \n",
    "        \n",
    "        print(\"U May Like These Movies \\n\\n\")\n",
    "        \n",
    "        for i in range(no_of_movies):\n",
    "            print(movies_list[i])\n",
    "            \n",
    "        return movies_list[:no_of_movies]\n",
    "            \n",
    "    def based_on_ratings(self,movieId):\n",
    "        avg_ratings = self.dataset.groupby(\"title\")['rating'].mean()\n",
    "        count = self.dataset.groupby(\"title\")['rating'].count()\n",
    "        dataset_based_on_ratings = pd.DataFrame({\"rating\":avg_ratings,\"number of ratings\":count})\n",
    "        \n",
    "        \n",
    "        df = self.dataset.loc[:,[\"userId\",\"rating\",\"title\"]]\n",
    "        users_movie_matrix = pd.pivot_table(df,columns='title',index='userId',values='rating') \n",
    "        \n",
    "        \n",
    "        movie_watched = users_movie_matrix[self.get_movie_by_id(movieId)]\n",
    "        li = []\n",
    "        for i in range(len(users_movie_matrix.columns)):\n",
    "            li.append(movie_watched.corr(users_movie_matrix.iloc[:,i]))\n",
    "        li = pd.Series(li)\n",
    "        \n",
    "        \n",
    "        df = pd.DataFrame({\"title\": users_movie_matrix.columns,\"Correlation\": li,\"number of ratings\" : dataset_based_on_ratings[\"number of ratings\"].values})\n",
    "        recommendation_set = df[df[\"number of ratings\"] >= 50].sort_values(by=[\"Correlation\",\"number of ratings\"],ascending=False)\n",
    "        \n",
    "        recommended_movies = recommendation_set[\"title\"].values\n",
    "        print(\"Movies which have similar ratings like given movie --->\",self.get_movie_by_id(movieId),\"<--- are\",end=\"\\n\\n\")\n",
    "        \n",
    "        for i in range(1,16):\n",
    "            print(recommended_movies[i])\n",
    "            \n",
    "        \n",
    "    def recommend(self,user_id=None,movie_id=None):\n",
    "        if movie_id is None and user_id is None:\n",
    "            print(\"Error, No user id or movie id found\")\n",
    "        elif user_id is not None and movie_id is not None:\n",
    "            self.content_based_filtering(user_id)           \n",
    "            print(\"\\n\\n\\n\")\n",
    "            self.collaborative_filtering(user_id)\n",
    "            print(\"\\n\\n\\n\")\n",
    "            self.based_on_ratings(movie_id)\n",
    "        elif user_id is None and movie_id is not None:\n",
    "            self.based_on_ratings(movie_id)\n",
    "        else:\n",
    "            self.content_based_filtering(user_id)\n",
    "            print(\"\\n\\n\\n\")\n",
    "            self.collaborative_filtering(user_id)\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error, No user id or movie id found\n"
     ]
    }
   ],
   "source": [
    "rs = RecommendationSystem()\n",
    "\n",
    "rs.recommend(user_id = )\n",
    "rs.recommend(user_id = ,movie_id)\n",
    "rs.recommend(movie_id= )\n",
    "rs.recommend() #This line gives error"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
